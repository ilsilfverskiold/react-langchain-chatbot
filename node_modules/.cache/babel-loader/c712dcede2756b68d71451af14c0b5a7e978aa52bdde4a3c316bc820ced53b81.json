{"ast":null,"code":"import { __publicField } from './chunk-XXPGZHWZ.js';\nimport base64 from 'base64-js';\n\n// src/utils.ts\nfunction never(_) {}\nfunction bytePairMerge(piece, ranks) {\n  let parts = Array.from({\n    length: piece.length\n  }, (_, i) => ({\n    start: i,\n    end: i + 1\n  }));\n  while (parts.length > 1) {\n    let minRank = null;\n    for (let i = 0; i < parts.length - 1; i++) {\n      const slice = piece.slice(parts[i].start, parts[i + 1].end);\n      const rank = ranks.get(slice.join(\",\"));\n      if (rank == null) continue;\n      if (minRank == null || rank < minRank[0]) {\n        minRank = [rank, i];\n      }\n    }\n    if (minRank != null) {\n      const i = minRank[1];\n      parts[i] = {\n        start: parts[i].start,\n        end: parts[i + 1].end\n      };\n      parts.splice(i + 1, 1);\n    } else {\n      break;\n    }\n  }\n  return parts;\n}\nfunction bytePairEncode(piece, ranks) {\n  if (piece.length === 1) return [ranks.get(piece.join(\",\"))];\n  return bytePairMerge(piece, ranks).map(p => ranks.get(piece.slice(p.start, p.end).join(\",\"))).filter(x => x != null);\n}\nfunction escapeRegex(str) {\n  return str.replace(/[\\\\^$*+?.()|[\\]{}]/g, \"\\\\$&\");\n}\nvar _Tiktoken = class {\n  /** @internal */\n  specialTokens;\n  /** @internal */\n  inverseSpecialTokens;\n  /** @internal */\n  patStr;\n  /** @internal */\n  textEncoder = new TextEncoder();\n  /** @internal */\n  textDecoder = new TextDecoder(\"utf-8\");\n  /** @internal */\n  rankMap = /* @__PURE__ */new Map();\n  /** @internal */\n  textMap = /* @__PURE__ */new Map();\n  constructor(ranks, extendedSpecialTokens) {\n    this.patStr = ranks.pat_str;\n    const uncompressed = ranks.bpe_ranks.split(\"\\n\").filter(Boolean).reduce((memo, x) => {\n      const [_, offsetStr, ...tokens] = x.split(\" \");\n      const offset = Number.parseInt(offsetStr, 10);\n      tokens.forEach((token, i) => memo[token] = offset + i);\n      return memo;\n    }, {});\n    for (const [token, rank] of Object.entries(uncompressed)) {\n      const bytes = base64.toByteArray(token);\n      this.rankMap.set(bytes.join(\",\"), rank);\n      this.textMap.set(rank, bytes);\n    }\n    this.specialTokens = {\n      ...ranks.special_tokens,\n      ...extendedSpecialTokens\n    };\n    this.inverseSpecialTokens = Object.entries(this.specialTokens).reduce((memo, [text, rank]) => {\n      memo[rank] = this.textEncoder.encode(text);\n      return memo;\n    }, {});\n  }\n  encode(text, allowedSpecial = [], disallowedSpecial = \"all\") {\n    const regexes = new RegExp(this.patStr, \"ug\");\n    const specialRegex = _Tiktoken.specialTokenRegex(Object.keys(this.specialTokens));\n    const ret = [];\n    const allowedSpecialSet = new Set(allowedSpecial === \"all\" ? Object.keys(this.specialTokens) : allowedSpecial);\n    const disallowedSpecialSet = new Set(disallowedSpecial === \"all\" ? Object.keys(this.specialTokens).filter(x => !allowedSpecialSet.has(x)) : disallowedSpecial);\n    if (disallowedSpecialSet.size > 0) {\n      const disallowedSpecialRegex = _Tiktoken.specialTokenRegex([...disallowedSpecialSet]);\n      const specialMatch = text.match(disallowedSpecialRegex);\n      if (specialMatch != null) {\n        throw new Error(`The text contains a special token that is not allowed: ${specialMatch[0]}`);\n      }\n    }\n    let start = 0;\n    while (true) {\n      let nextSpecial = null;\n      let startFind = start;\n      while (true) {\n        specialRegex.lastIndex = startFind;\n        nextSpecial = specialRegex.exec(text);\n        if (nextSpecial == null || allowedSpecialSet.has(nextSpecial[0])) break;\n        startFind = nextSpecial.index + 1;\n      }\n      const end = nextSpecial?.index ?? text.length;\n      for (const match of text.substring(start, end).matchAll(regexes)) {\n        const piece = this.textEncoder.encode(match[0]);\n        const token2 = this.rankMap.get(piece.join(\",\"));\n        if (token2 != null) {\n          ret.push(token2);\n          continue;\n        }\n        ret.push(...bytePairEncode(piece, this.rankMap));\n      }\n      if (nextSpecial == null) break;\n      let token = this.specialTokens[nextSpecial[0]];\n      ret.push(token);\n      start = nextSpecial.index + nextSpecial[0].length;\n    }\n    return ret;\n  }\n  decode(tokens) {\n    const res = [];\n    let length = 0;\n    for (let i2 = 0; i2 < tokens.length; ++i2) {\n      const token = tokens[i2];\n      const bytes = this.textMap.get(token) ?? this.inverseSpecialTokens[token];\n      if (bytes != null) {\n        res.push(bytes);\n        length += bytes.length;\n      }\n    }\n    const mergedArray = new Uint8Array(length);\n    let i = 0;\n    for (const bytes of res) {\n      mergedArray.set(bytes, i);\n      i += bytes.length;\n    }\n    return this.textDecoder.decode(mergedArray);\n  }\n};\nvar Tiktoken = _Tiktoken;\n__publicField(Tiktoken, \"specialTokenRegex\", tokens => {\n  return new RegExp(tokens.map(i => escapeRegex(i)).join(\"|\"), \"g\");\n});\nfunction getEncodingNameForModel(model) {\n  switch (model) {\n    case \"gpt2\":\n      {\n        return \"gpt2\";\n      }\n    case \"code-cushman-001\":\n    case \"code-cushman-002\":\n    case \"code-davinci-001\":\n    case \"code-davinci-002\":\n    case \"cushman-codex\":\n    case \"davinci-codex\":\n    case \"text-davinci-002\":\n    case \"text-davinci-003\":\n      {\n        return \"p50k_base\";\n      }\n    case \"code-davinci-edit-001\":\n    case \"text-davinci-edit-001\":\n      {\n        return \"p50k_edit\";\n      }\n    case \"ada\":\n    case \"babbage\":\n    case \"code-search-ada-code-001\":\n    case \"code-search-babbage-code-001\":\n    case \"curie\":\n    case \"davinci\":\n    case \"text-ada-001\":\n    case \"text-babbage-001\":\n    case \"text-curie-001\":\n    case \"text-davinci-001\":\n    case \"text-search-ada-doc-001\":\n    case \"text-search-babbage-doc-001\":\n    case \"text-search-curie-doc-001\":\n    case \"text-search-davinci-doc-001\":\n    case \"text-similarity-ada-001\":\n    case \"text-similarity-babbage-001\":\n    case \"text-similarity-curie-001\":\n    case \"text-similarity-davinci-001\":\n      {\n        return \"r50k_base\";\n      }\n    case \"gpt-3.5-turbo-16k-0613\":\n    case \"gpt-3.5-turbo-16k\":\n    case \"gpt-3.5-turbo-0613\":\n    case \"gpt-3.5-turbo-0301\":\n    case \"gpt-3.5-turbo\":\n    case \"gpt-4-32k-0613\":\n    case \"gpt-4-32k-0314\":\n    case \"gpt-4-32k\":\n    case \"gpt-4-0613\":\n    case \"gpt-4-0314\":\n    case \"gpt-4\":\n    case \"text-embedding-ada-002\":\n      {\n        return \"cl100k_base\";\n      }\n    default:\n      throw new Error(\"Unknown model\");\n  }\n}\nexport { Tiktoken, getEncodingNameForModel, never };","map":{"version":3,"names":["__publicField","base64","never","_","bytePairMerge","piece","ranks","parts","Array","from","length","i","start","end","minRank","slice","rank","get","join","splice","bytePairEncode","map","p","filter","x","escapeRegex","str","replace","_Tiktoken","specialTokens","inverseSpecialTokens","patStr","textEncoder","TextEncoder","textDecoder","TextDecoder","rankMap","Map","textMap","constructor","extendedSpecialTokens","pat_str","uncompressed","bpe_ranks","split","Boolean","reduce","memo","offsetStr","tokens","offset","Number","parseInt","forEach","token","Object","entries","bytes","toByteArray","set","special_tokens","text","encode","allowedSpecial","disallowedSpecial","regexes","RegExp","specialRegex","specialTokenRegex","keys","ret","allowedSpecialSet","Set","disallowedSpecialSet","has","size","disallowedSpecialRegex","specialMatch","match","Error","nextSpecial","startFind","lastIndex","exec","index","substring","matchAll","token2","push","decode","res","i2","mergedArray","Uint8Array","Tiktoken","getEncodingNameForModel","model"],"sources":["/Users/idasilfverskiold/gptSandbox/reactlangchain/sandbox/node_modules/js-tiktoken/dist/chunk-THGZSONF.js"],"sourcesContent":["import { __publicField } from './chunk-XXPGZHWZ.js';\nimport base64 from 'base64-js';\n\n// src/utils.ts\nfunction never(_) {\n}\nfunction bytePairMerge(piece, ranks) {\n  let parts = Array.from(\n    { length: piece.length },\n    (_, i) => ({ start: i, end: i + 1 })\n  );\n  while (parts.length > 1) {\n    let minRank = null;\n    for (let i = 0; i < parts.length - 1; i++) {\n      const slice = piece.slice(parts[i].start, parts[i + 1].end);\n      const rank = ranks.get(slice.join(\",\"));\n      if (rank == null)\n        continue;\n      if (minRank == null || rank < minRank[0]) {\n        minRank = [rank, i];\n      }\n    }\n    if (minRank != null) {\n      const i = minRank[1];\n      parts[i] = { start: parts[i].start, end: parts[i + 1].end };\n      parts.splice(i + 1, 1);\n    } else {\n      break;\n    }\n  }\n  return parts;\n}\nfunction bytePairEncode(piece, ranks) {\n  if (piece.length === 1)\n    return [ranks.get(piece.join(\",\"))];\n  return bytePairMerge(piece, ranks).map((p) => ranks.get(piece.slice(p.start, p.end).join(\",\"))).filter((x) => x != null);\n}\nfunction escapeRegex(str) {\n  return str.replace(/[\\\\^$*+?.()|[\\]{}]/g, \"\\\\$&\");\n}\nvar _Tiktoken = class {\n  /** @internal */\n  specialTokens;\n  /** @internal */\n  inverseSpecialTokens;\n  /** @internal */\n  patStr;\n  /** @internal */\n  textEncoder = new TextEncoder();\n  /** @internal */\n  textDecoder = new TextDecoder(\"utf-8\");\n  /** @internal */\n  rankMap = /* @__PURE__ */ new Map();\n  /** @internal */\n  textMap = /* @__PURE__ */ new Map();\n  constructor(ranks, extendedSpecialTokens) {\n    this.patStr = ranks.pat_str;\n    const uncompressed = ranks.bpe_ranks.split(\"\\n\").filter(Boolean).reduce((memo, x) => {\n      const [_, offsetStr, ...tokens] = x.split(\" \");\n      const offset = Number.parseInt(offsetStr, 10);\n      tokens.forEach((token, i) => memo[token] = offset + i);\n      return memo;\n    }, {});\n    for (const [token, rank] of Object.entries(uncompressed)) {\n      const bytes = base64.toByteArray(token);\n      this.rankMap.set(bytes.join(\",\"), rank);\n      this.textMap.set(rank, bytes);\n    }\n    this.specialTokens = { ...ranks.special_tokens, ...extendedSpecialTokens };\n    this.inverseSpecialTokens = Object.entries(this.specialTokens).reduce((memo, [text, rank]) => {\n      memo[rank] = this.textEncoder.encode(text);\n      return memo;\n    }, {});\n  }\n  encode(text, allowedSpecial = [], disallowedSpecial = \"all\") {\n    const regexes = new RegExp(this.patStr, \"ug\");\n    const specialRegex = _Tiktoken.specialTokenRegex(\n      Object.keys(this.specialTokens)\n    );\n    const ret = [];\n    const allowedSpecialSet = new Set(\n      allowedSpecial === \"all\" ? Object.keys(this.specialTokens) : allowedSpecial\n    );\n    const disallowedSpecialSet = new Set(\n      disallowedSpecial === \"all\" ? Object.keys(this.specialTokens).filter(\n        (x) => !allowedSpecialSet.has(x)\n      ) : disallowedSpecial\n    );\n    if (disallowedSpecialSet.size > 0) {\n      const disallowedSpecialRegex = _Tiktoken.specialTokenRegex([\n        ...disallowedSpecialSet\n      ]);\n      const specialMatch = text.match(disallowedSpecialRegex);\n      if (specialMatch != null) {\n        throw new Error(\n          `The text contains a special token that is not allowed: ${specialMatch[0]}`\n        );\n      }\n    }\n    let start = 0;\n    while (true) {\n      let nextSpecial = null;\n      let startFind = start;\n      while (true) {\n        specialRegex.lastIndex = startFind;\n        nextSpecial = specialRegex.exec(text);\n        if (nextSpecial == null || allowedSpecialSet.has(nextSpecial[0]))\n          break;\n        startFind = nextSpecial.index + 1;\n      }\n      const end = nextSpecial?.index ?? text.length;\n      for (const match of text.substring(start, end).matchAll(regexes)) {\n        const piece = this.textEncoder.encode(match[0]);\n        const token2 = this.rankMap.get(piece.join(\",\"));\n        if (token2 != null) {\n          ret.push(token2);\n          continue;\n        }\n        ret.push(...bytePairEncode(piece, this.rankMap));\n      }\n      if (nextSpecial == null)\n        break;\n      let token = this.specialTokens[nextSpecial[0]];\n      ret.push(token);\n      start = nextSpecial.index + nextSpecial[0].length;\n    }\n    return ret;\n  }\n  decode(tokens) {\n    const res = [];\n    let length = 0;\n    for (let i2 = 0; i2 < tokens.length; ++i2) {\n      const token = tokens[i2];\n      const bytes = this.textMap.get(token) ?? this.inverseSpecialTokens[token];\n      if (bytes != null) {\n        res.push(bytes);\n        length += bytes.length;\n      }\n    }\n    const mergedArray = new Uint8Array(length);\n    let i = 0;\n    for (const bytes of res) {\n      mergedArray.set(bytes, i);\n      i += bytes.length;\n    }\n    return this.textDecoder.decode(mergedArray);\n  }\n};\nvar Tiktoken = _Tiktoken;\n__publicField(Tiktoken, \"specialTokenRegex\", (tokens) => {\n  return new RegExp(tokens.map((i) => escapeRegex(i)).join(\"|\"), \"g\");\n});\nfunction getEncodingNameForModel(model) {\n  switch (model) {\n    case \"gpt2\": {\n      return \"gpt2\";\n    }\n    case \"code-cushman-001\":\n    case \"code-cushman-002\":\n    case \"code-davinci-001\":\n    case \"code-davinci-002\":\n    case \"cushman-codex\":\n    case \"davinci-codex\":\n    case \"text-davinci-002\":\n    case \"text-davinci-003\": {\n      return \"p50k_base\";\n    }\n    case \"code-davinci-edit-001\":\n    case \"text-davinci-edit-001\": {\n      return \"p50k_edit\";\n    }\n    case \"ada\":\n    case \"babbage\":\n    case \"code-search-ada-code-001\":\n    case \"code-search-babbage-code-001\":\n    case \"curie\":\n    case \"davinci\":\n    case \"text-ada-001\":\n    case \"text-babbage-001\":\n    case \"text-curie-001\":\n    case \"text-davinci-001\":\n    case \"text-search-ada-doc-001\":\n    case \"text-search-babbage-doc-001\":\n    case \"text-search-curie-doc-001\":\n    case \"text-search-davinci-doc-001\":\n    case \"text-similarity-ada-001\":\n    case \"text-similarity-babbage-001\":\n    case \"text-similarity-curie-001\":\n    case \"text-similarity-davinci-001\": {\n      return \"r50k_base\";\n    }\n    case \"gpt-3.5-turbo-16k-0613\":\n    case \"gpt-3.5-turbo-16k\":\n    case \"gpt-3.5-turbo-0613\":\n    case \"gpt-3.5-turbo-0301\":\n    case \"gpt-3.5-turbo\":\n    case \"gpt-4-32k-0613\":\n    case \"gpt-4-32k-0314\":\n    case \"gpt-4-32k\":\n    case \"gpt-4-0613\":\n    case \"gpt-4-0314\":\n    case \"gpt-4\":\n    case \"text-embedding-ada-002\": {\n      return \"cl100k_base\";\n    }\n    default:\n      throw new Error(\"Unknown model\");\n  }\n}\n\nexport { Tiktoken, getEncodingNameForModel, never };\n"],"mappings":"AAAA,SAASA,aAAa,QAAQ,qBAAqB;AACnD,OAAOC,MAAM,MAAM,WAAW;;AAE9B;AACA,SAASC,KAAKA,CAACC,CAAC,EAAE,CAClB;AACA,SAASC,aAAaA,CAACC,KAAK,EAAEC,KAAK,EAAE;EACnC,IAAIC,KAAK,GAAGC,KAAK,CAACC,IAAI,CACpB;IAAEC,MAAM,EAAEL,KAAK,CAACK;EAAO,CAAC,EACxB,CAACP,CAAC,EAAEQ,CAAC,MAAM;IAAEC,KAAK,EAAED,CAAC;IAAEE,GAAG,EAAEF,CAAC,GAAG;EAAE,CAAC,CACrC,CAAC;EACD,OAAOJ,KAAK,CAACG,MAAM,GAAG,CAAC,EAAE;IACvB,IAAII,OAAO,GAAG,IAAI;IAClB,KAAK,IAAIH,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,KAAK,CAACG,MAAM,GAAG,CAAC,EAAEC,CAAC,EAAE,EAAE;MACzC,MAAMI,KAAK,GAAGV,KAAK,CAACU,KAAK,CAACR,KAAK,CAACI,CAAC,CAAC,CAACC,KAAK,EAAEL,KAAK,CAACI,CAAC,GAAG,CAAC,CAAC,CAACE,GAAG,CAAC;MAC3D,MAAMG,IAAI,GAAGV,KAAK,CAACW,GAAG,CAACF,KAAK,CAACG,IAAI,CAAC,GAAG,CAAC,CAAC;MACvC,IAAIF,IAAI,IAAI,IAAI,EACd;MACF,IAAIF,OAAO,IAAI,IAAI,IAAIE,IAAI,GAAGF,OAAO,CAAC,CAAC,CAAC,EAAE;QACxCA,OAAO,GAAG,CAACE,IAAI,EAAEL,CAAC,CAAC;MACrB;IACF;IACA,IAAIG,OAAO,IAAI,IAAI,EAAE;MACnB,MAAMH,CAAC,GAAGG,OAAO,CAAC,CAAC,CAAC;MACpBP,KAAK,CAACI,CAAC,CAAC,GAAG;QAAEC,KAAK,EAAEL,KAAK,CAACI,CAAC,CAAC,CAACC,KAAK;QAAEC,GAAG,EAAEN,KAAK,CAACI,CAAC,GAAG,CAAC,CAAC,CAACE;MAAI,CAAC;MAC3DN,KAAK,CAACY,MAAM,CAACR,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC;IACxB,CAAC,MAAM;MACL;IACF;EACF;EACA,OAAOJ,KAAK;AACd;AACA,SAASa,cAAcA,CAACf,KAAK,EAAEC,KAAK,EAAE;EACpC,IAAID,KAAK,CAACK,MAAM,KAAK,CAAC,EACpB,OAAO,CAACJ,KAAK,CAACW,GAAG,CAACZ,KAAK,CAACa,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;EACrC,OAAOd,aAAa,CAACC,KAAK,EAAEC,KAAK,CAAC,CAACe,GAAG,CAAEC,CAAC,IAAKhB,KAAK,CAACW,GAAG,CAACZ,KAAK,CAACU,KAAK,CAACO,CAAC,CAACV,KAAK,EAAEU,CAAC,CAACT,GAAG,CAAC,CAACK,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAACK,MAAM,CAAEC,CAAC,IAAKA,CAAC,IAAI,IAAI,CAAC;AAC1H;AACA,SAASC,WAAWA,CAACC,GAAG,EAAE;EACxB,OAAOA,GAAG,CAACC,OAAO,CAAC,qBAAqB,EAAE,MAAM,CAAC;AACnD;AACA,IAAIC,SAAS,GAAG,MAAM;EACpB;EACAC,aAAa;EACb;EACAC,oBAAoB;EACpB;EACAC,MAAM;EACN;EACAC,WAAW,GAAG,IAAIC,WAAW,CAAC,CAAC;EAC/B;EACAC,WAAW,GAAG,IAAIC,WAAW,CAAC,OAAO,CAAC;EACtC;EACAC,OAAO,GAAG,eAAgB,IAAIC,GAAG,CAAC,CAAC;EACnC;EACAC,OAAO,GAAG,eAAgB,IAAID,GAAG,CAAC,CAAC;EACnCE,WAAWA,CAACjC,KAAK,EAAEkC,qBAAqB,EAAE;IACxC,IAAI,CAACT,MAAM,GAAGzB,KAAK,CAACmC,OAAO;IAC3B,MAAMC,YAAY,GAAGpC,KAAK,CAACqC,SAAS,CAACC,KAAK,CAAC,IAAI,CAAC,CAACrB,MAAM,CAACsB,OAAO,CAAC,CAACC,MAAM,CAAC,CAACC,IAAI,EAAEvB,CAAC,KAAK;MACnF,MAAM,CAACrB,CAAC,EAAE6C,SAAS,EAAE,GAAGC,MAAM,CAAC,GAAGzB,CAAC,CAACoB,KAAK,CAAC,GAAG,CAAC;MAC9C,MAAMM,MAAM,GAAGC,MAAM,CAACC,QAAQ,CAACJ,SAAS,EAAE,EAAE,CAAC;MAC7CC,MAAM,CAACI,OAAO,CAAC,CAACC,KAAK,EAAE3C,CAAC,KAAKoC,IAAI,CAACO,KAAK,CAAC,GAAGJ,MAAM,GAAGvC,CAAC,CAAC;MACtD,OAAOoC,IAAI;IACb,CAAC,EAAE,CAAC,CAAC,CAAC;IACN,KAAK,MAAM,CAACO,KAAK,EAAEtC,IAAI,CAAC,IAAIuC,MAAM,CAACC,OAAO,CAACd,YAAY,CAAC,EAAE;MACxD,MAAMe,KAAK,GAAGxD,MAAM,CAACyD,WAAW,CAACJ,KAAK,CAAC;MACvC,IAAI,CAAClB,OAAO,CAACuB,GAAG,CAACF,KAAK,CAACvC,IAAI,CAAC,GAAG,CAAC,EAAEF,IAAI,CAAC;MACvC,IAAI,CAACsB,OAAO,CAACqB,GAAG,CAAC3C,IAAI,EAAEyC,KAAK,CAAC;IAC/B;IACA,IAAI,CAAC5B,aAAa,GAAG;MAAE,GAAGvB,KAAK,CAACsD,cAAc;MAAE,GAAGpB;IAAsB,CAAC;IAC1E,IAAI,CAACV,oBAAoB,GAAGyB,MAAM,CAACC,OAAO,CAAC,IAAI,CAAC3B,aAAa,CAAC,CAACiB,MAAM,CAAC,CAACC,IAAI,EAAE,CAACc,IAAI,EAAE7C,IAAI,CAAC,KAAK;MAC5F+B,IAAI,CAAC/B,IAAI,CAAC,GAAG,IAAI,CAACgB,WAAW,CAAC8B,MAAM,CAACD,IAAI,CAAC;MAC1C,OAAOd,IAAI;IACb,CAAC,EAAE,CAAC,CAAC,CAAC;EACR;EACAe,MAAMA,CAACD,IAAI,EAAEE,cAAc,GAAG,EAAE,EAAEC,iBAAiB,GAAG,KAAK,EAAE;IAC3D,MAAMC,OAAO,GAAG,IAAIC,MAAM,CAAC,IAAI,CAACnC,MAAM,EAAE,IAAI,CAAC;IAC7C,MAAMoC,YAAY,GAAGvC,SAAS,CAACwC,iBAAiB,CAC9Cb,MAAM,CAACc,IAAI,CAAC,IAAI,CAACxC,aAAa,CAChC,CAAC;IACD,MAAMyC,GAAG,GAAG,EAAE;IACd,MAAMC,iBAAiB,GAAG,IAAIC,GAAG,CAC/BT,cAAc,KAAK,KAAK,GAAGR,MAAM,CAACc,IAAI,CAAC,IAAI,CAACxC,aAAa,CAAC,GAAGkC,cAC/D,CAAC;IACD,MAAMU,oBAAoB,GAAG,IAAID,GAAG,CAClCR,iBAAiB,KAAK,KAAK,GAAGT,MAAM,CAACc,IAAI,CAAC,IAAI,CAACxC,aAAa,CAAC,CAACN,MAAM,CACjEC,CAAC,IAAK,CAAC+C,iBAAiB,CAACG,GAAG,CAAClD,CAAC,CACjC,CAAC,GAAGwC,iBACN,CAAC;IACD,IAAIS,oBAAoB,CAACE,IAAI,GAAG,CAAC,EAAE;MACjC,MAAMC,sBAAsB,GAAGhD,SAAS,CAACwC,iBAAiB,CAAC,CACzD,GAAGK,oBAAoB,CACxB,CAAC;MACF,MAAMI,YAAY,GAAGhB,IAAI,CAACiB,KAAK,CAACF,sBAAsB,CAAC;MACvD,IAAIC,YAAY,IAAI,IAAI,EAAE;QACxB,MAAM,IAAIE,KAAK,CACZ,0DAAyDF,YAAY,CAAC,CAAC,CAAE,EAC5E,CAAC;MACH;IACF;IACA,IAAIjE,KAAK,GAAG,CAAC;IACb,OAAO,IAAI,EAAE;MACX,IAAIoE,WAAW,GAAG,IAAI;MACtB,IAAIC,SAAS,GAAGrE,KAAK;MACrB,OAAO,IAAI,EAAE;QACXuD,YAAY,CAACe,SAAS,GAAGD,SAAS;QAClCD,WAAW,GAAGb,YAAY,CAACgB,IAAI,CAACtB,IAAI,CAAC;QACrC,IAAImB,WAAW,IAAI,IAAI,IAAIT,iBAAiB,CAACG,GAAG,CAACM,WAAW,CAAC,CAAC,CAAC,CAAC,EAC9D;QACFC,SAAS,GAAGD,WAAW,CAACI,KAAK,GAAG,CAAC;MACnC;MACA,MAAMvE,GAAG,GAAGmE,WAAW,EAAEI,KAAK,IAAIvB,IAAI,CAACnD,MAAM;MAC7C,KAAK,MAAMoE,KAAK,IAAIjB,IAAI,CAACwB,SAAS,CAACzE,KAAK,EAAEC,GAAG,CAAC,CAACyE,QAAQ,CAACrB,OAAO,CAAC,EAAE;QAChE,MAAM5D,KAAK,GAAG,IAAI,CAAC2B,WAAW,CAAC8B,MAAM,CAACgB,KAAK,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAMS,MAAM,GAAG,IAAI,CAACnD,OAAO,CAACnB,GAAG,CAACZ,KAAK,CAACa,IAAI,CAAC,GAAG,CAAC,CAAC;QAChD,IAAIqE,MAAM,IAAI,IAAI,EAAE;UAClBjB,GAAG,CAACkB,IAAI,CAACD,MAAM,CAAC;UAChB;QACF;QACAjB,GAAG,CAACkB,IAAI,CAAC,GAAGpE,cAAc,CAACf,KAAK,EAAE,IAAI,CAAC+B,OAAO,CAAC,CAAC;MAClD;MACA,IAAI4C,WAAW,IAAI,IAAI,EACrB;MACF,IAAI1B,KAAK,GAAG,IAAI,CAACzB,aAAa,CAACmD,WAAW,CAAC,CAAC,CAAC,CAAC;MAC9CV,GAAG,CAACkB,IAAI,CAAClC,KAAK,CAAC;MACf1C,KAAK,GAAGoE,WAAW,CAACI,KAAK,GAAGJ,WAAW,CAAC,CAAC,CAAC,CAACtE,MAAM;IACnD;IACA,OAAO4D,GAAG;EACZ;EACAmB,MAAMA,CAACxC,MAAM,EAAE;IACb,MAAMyC,GAAG,GAAG,EAAE;IACd,IAAIhF,MAAM,GAAG,CAAC;IACd,KAAK,IAAIiF,EAAE,GAAG,CAAC,EAAEA,EAAE,GAAG1C,MAAM,CAACvC,MAAM,EAAE,EAAEiF,EAAE,EAAE;MACzC,MAAMrC,KAAK,GAAGL,MAAM,CAAC0C,EAAE,CAAC;MACxB,MAAMlC,KAAK,GAAG,IAAI,CAACnB,OAAO,CAACrB,GAAG,CAACqC,KAAK,CAAC,IAAI,IAAI,CAACxB,oBAAoB,CAACwB,KAAK,CAAC;MACzE,IAAIG,KAAK,IAAI,IAAI,EAAE;QACjBiC,GAAG,CAACF,IAAI,CAAC/B,KAAK,CAAC;QACf/C,MAAM,IAAI+C,KAAK,CAAC/C,MAAM;MACxB;IACF;IACA,MAAMkF,WAAW,GAAG,IAAIC,UAAU,CAACnF,MAAM,CAAC;IAC1C,IAAIC,CAAC,GAAG,CAAC;IACT,KAAK,MAAM8C,KAAK,IAAIiC,GAAG,EAAE;MACvBE,WAAW,CAACjC,GAAG,CAACF,KAAK,EAAE9C,CAAC,CAAC;MACzBA,CAAC,IAAI8C,KAAK,CAAC/C,MAAM;IACnB;IACA,OAAO,IAAI,CAACwB,WAAW,CAACuD,MAAM,CAACG,WAAW,CAAC;EAC7C;AACF,CAAC;AACD,IAAIE,QAAQ,GAAGlE,SAAS;AACxB5B,aAAa,CAAC8F,QAAQ,EAAE,mBAAmB,EAAG7C,MAAM,IAAK;EACvD,OAAO,IAAIiB,MAAM,CAACjB,MAAM,CAAC5B,GAAG,CAAEV,CAAC,IAAKc,WAAW,CAACd,CAAC,CAAC,CAAC,CAACO,IAAI,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC;AACrE,CAAC,CAAC;AACF,SAAS6E,uBAAuBA,CAACC,KAAK,EAAE;EACtC,QAAQA,KAAK;IACX,KAAK,MAAM;MAAE;QACX,OAAO,MAAM;MACf;IACA,KAAK,kBAAkB;IACvB,KAAK,kBAAkB;IACvB,KAAK,kBAAkB;IACvB,KAAK,kBAAkB;IACvB,KAAK,eAAe;IACpB,KAAK,eAAe;IACpB,KAAK,kBAAkB;IACvB,KAAK,kBAAkB;MAAE;QACvB,OAAO,WAAW;MACpB;IACA,KAAK,uBAAuB;IAC5B,KAAK,uBAAuB;MAAE;QAC5B,OAAO,WAAW;MACpB;IACA,KAAK,KAAK;IACV,KAAK,SAAS;IACd,KAAK,0BAA0B;IAC/B,KAAK,8BAA8B;IACnC,KAAK,OAAO;IACZ,KAAK,SAAS;IACd,KAAK,cAAc;IACnB,KAAK,kBAAkB;IACvB,KAAK,gBAAgB;IACrB,KAAK,kBAAkB;IACvB,KAAK,yBAAyB;IAC9B,KAAK,6BAA6B;IAClC,KAAK,2BAA2B;IAChC,KAAK,6BAA6B;IAClC,KAAK,yBAAyB;IAC9B,KAAK,6BAA6B;IAClC,KAAK,2BAA2B;IAChC,KAAK,6BAA6B;MAAE;QAClC,OAAO,WAAW;MACpB;IACA,KAAK,wBAAwB;IAC7B,KAAK,mBAAmB;IACxB,KAAK,oBAAoB;IACzB,KAAK,oBAAoB;IACzB,KAAK,eAAe;IACpB,KAAK,gBAAgB;IACrB,KAAK,gBAAgB;IACrB,KAAK,WAAW;IAChB,KAAK,YAAY;IACjB,KAAK,YAAY;IACjB,KAAK,OAAO;IACZ,KAAK,wBAAwB;MAAE;QAC7B,OAAO,aAAa;MACtB;IACA;MACE,MAAM,IAAIjB,KAAK,CAAC,eAAe,CAAC;EACpC;AACF;AAEA,SAASe,QAAQ,EAAEC,uBAAuB,EAAE7F,KAAK"},"metadata":{},"sourceType":"module","externalDependencies":[]}